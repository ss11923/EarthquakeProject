### Earthquake Data Analysis - Final Project (Statistics for Data Science)

## Project Overview

This project focuses on analyzing a global earthquake dataset (earthquakes.csv) to uncover key insights into the magnitude, depth, and distribution of seismic activities worldwide. The project was completed as part of the Statistics for Data Science course in Year 1 at the University of Bath.

Using Python libraries such as Pandas for data manipulation and Matplotlib/Seaborn for visualization, the analysis provided valuable information that can be used for disaster management and urban planning, particularly in high-risk regions like Japan, Alaska, and California. The findings culminated in a short policy paper with recommendations for policymakers.

## Key Features

Data Cleaning and Preparation: Utilized Pandas to handle missing values, duplicate records, and outliers to ensure the dataset was ready for analysis.
Statistical Analysis: Computed statistical summaries to understand earthquake distributions across various regions, including magnitude, depth, and frequency.
Data Visualization: Created detailed visualizations using Matplotlib and Seaborn to identify patterns and trends, such as geographic clustering of earthquakes along tectonic plate boundaries.
Policy Recommendations: Based on the findings, a policy paper was produced, suggesting resource allocation strategies for governments in earthquake-prone areas.

## Tools & Libraries

Pandas for data manipulation and analysis
Matplotlib and Seaborn for data visualization
Jupyter Notebook for interactive coding and analysis

## Results & Insights

Magnitude Distribution: The average earthquake magnitude in North America was significantly lower than in regions like East Asia and South America.
Geographic Clustering: The majority of earthquakes occurred along tectonic plate boundaries, particularly in the Pacific 'Ring of Fire.'
Policy Implications: The analysis suggested that deeper earthquakes result in less surface damage, and therefore should be factored into resource planning and infrastructure development.

## Next Steps
Expand the temporal scope of the dataset to perform time-based analysis (e.g., seasonality effects on earthquake occurrence).
Improve data labeling to ensure clarity in ambiguous columns like "impact significance."
